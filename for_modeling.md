### model evaluation
假设 测试样本是从样本真实分布中独立同分布采样而得。数据集划分过程尽可能保持数据分布的一致性，从采样角度看，保留类别比例的采样方法
称为**分层采样(stratified sampling)**.)

使用一个`testing set`来测试学习器对新样本的判别能力，以测试集上的`测试误差`作为泛化误差的近似。保证测试集尽可能与训练集互斥。
+ 1 hold-out evaluation

“留出法”（hold-out）直接将数据集D划分为两个互斥的集合(通常三七开)，其中一个集合作为训练集S， 另一个作为测试集T， 
即D = S∪T,  S∩T = ∅. 在S上训练出模型后， 用T来评估其测试误差，作为对泛化误差的估计.**单次使用留出法得到的估计结果往往不够稳定，因此一般
采用若干次随机划分、重复进行试验评估后取平均值作为留出法的评估结果**。
+ 2 cross validation(k-fold cross validation)

现将数据集D划分为k个大小相似的互斥子集，即 D = D1∪D2∪……∪Dk，Di∩Dj = ∅(i≠j)。每个子集尽可能保持数据分布的一致性，
即从D中通过分层采样得到，然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集。如此，**获得k组训练/测试集，
可进行k次训练和测试，最终返回k次测试结果的均值**。一般要**随机使用不同的划分，重复p次3，最终评估结果是这p次k折交叉验证
结果的均值**，例如：10次10折交叉验证。

若数据集D中包含m个样本，令k=m，则得到了交叉验证法的一个特例：留一法(leave-one-out)。
+ 3 booststramping

给定包含m个样本的数据集D，对它进行采样产生数据集D':每次随机从D中挑选一个样本，将其拷贝放入D',然后再将该样本放回
初始数据集D中，使得该样本在下次采样时仍有可能被采到；此过程重复执行m次后，可得到一个包含m个样本的数据集D'。

样本在m次采样中，始终不被采到的概率是
$$ \lim_{m \mapsto  \infty }(1-\frac{1}{m})^{m}\rightarrow \frac{1}{e}\approx 0.368 $$
即，通过自主采样，初始数据集D中约有36.8%的样本未出现在采样数据集D'中。因此，我们可将D'用作训练集，D\D'用作测试集。

booststramping在数据集较小、难以有效划分训练/测试集时很有用。


