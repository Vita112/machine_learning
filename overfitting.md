## 1 什么是overfitting？
一个假设：机器学习中，假设训练数据集 与 验证集和测试集 是独立同分布(independently and identically distributed)的，使用已有数据进行模型训练，然后将得到的模型用于新的数据上，进行预测和推测。
**但是**，现实的数据不可能总是满足独立同分布，有时候我们现有的数据会非常少，不足以对整个数据集进行分布估计，导致在训练过程中，出现过拟合问题。一种情况是：随着模型复杂度的
增加，拟合后的误差是逐渐缩小的，但是，随着训练的继续，模型复杂度继续增加，模型在验证集上的误差反而越来越大。这种情况便是过拟合，即随着模型复杂度的增加，拟合后的误差在训练集
上减小，但其他数据集上却并未减小，甚至变得越来越大。
## 2 四大主要解决方法
### 2.1 early stopping
核心思想是：在出现过拟合之前，停止迭代。使用**迭代次数截断**的方法来防止或拟合，即模型对训练数据集进行迭代收敛之前，就停止迭代。在每一个Epoch结束时（一个Epoch集为对所有的
训练数据的一轮遍历）计算validation data的accuracy，当accuracy不再提高时，就停止训练。
### 2.2 regularization
+ lasso
+ ridge regression in linear regression
### 2.3 dropout
### 2.4 data augmentation
使用越多的训练数据得到的模型，其在测试集上将获得更高的精确度。有几种方法可以扩增训练数据集：
```
复制已有数据，为其增加噪声
重采样
根据当前数据集估计数据分布参数，使用参数分布生成数据
```


[reference](https://blog.csdn.net/heyongluoyao8/article/details/49429629)
