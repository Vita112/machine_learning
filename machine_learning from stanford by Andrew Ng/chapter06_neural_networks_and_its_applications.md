## 1 motivations
### 1.1 non-linear hypotheses
一个事实：现实生活中，我们需要非线性模型来解决更加复杂的问题。
+ 引例

假设现在有一个监督学习下的分类问题，数据只包含2个特征，此时使用高阶多项式作为我们的假设模型，构造一个包含很多非线性项的逻辑回归函数$h_{\theta }(x)=g(z)=g(\frac{1}{1+e^{-(\mathbf{\theta }^\mathrm{T}x)}})$,
z是一个高阶非线性函数，g(z)是sigmoid函数，这个模型可以将训练数据分为两类，完成分类任务。**但现实世界中，特征数总是大于2的，有时可能非常多**，比如假设有n=100个特征,此时特征二次项的个数为：<br>
$\frac{n^{2}}{2!}$=5000，三次项特征数为$\frac{n^{3}}{3!}$=17000。如果我们使用逻辑回归算法模型，如此多的特征项极易导致过拟合问题，而且计算量庞大computationally expensive。我们发现：<br>
随着初始特征数的增加，高阶多项式的项数以几何级数的速度增加。如果我们舍弃特征项的某些部分，比如只取二次项特征的一个子集，假设只取$x_{1}^{2},x_{2}^{2},\cdots ,x_{100}^{2}$，最后我们将得到一个类似椭圆的分类决策边界，显然这不是一个好的模型，因为它忽略了太多的特征信息。
+ car detectation task
可以看成是 通过图片的像素点亮度矩阵来告诉我们它代表了汽车的哪个部位。**基本思想**是：使用一个带标签的样本集，其中包括汽车和汽车以外的物体的图片，使用学习算法对样本集进行训练，以得到一个分类器，这个分类器在接受新的样本输入时，能够识别出 它是不是一辆汽车。
> zoom目标图片中的一小部分，我们假设它是一个50×50的像素图片，于是我们得到n=2500个像素点，特征向量x是一个包含所有2500个像素点的像素强度值，这个例子是灰度图片grayscale images的情况，**当使用RGB彩色图片时**，那么我们将得到n=75000个像素点。此时，二次项特征的个数将达到$\frac{n^{2}}{2!}\approx 3,000,00$,这个数字太大了，对于每个样本来说，要发现并表示所有这300万个项的计算成本太高！！
```
像素强度值pixel indensity values：告诉我们图片中每个像素点的亮度值或称灰度值(表示色彩的强烈程度)，
在典型的计算机图片表示方法中，取值范围在0~255之间。
```
### 1.2 neurons and the brain

## 2 neural networks
### 2.1 model representation Ⅰ
### 2.2 model representation Ⅱ
## 3 applications
### 3.1 examples and intuitions Ⅰ
### 3.2 examples and intuitions Ⅱ
### 3.3 multiclass classification
