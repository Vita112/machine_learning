机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型”的算法，即**学习算法(learning algorithm)**.

## 1.1 基本术语
**示例或样本(instance or sample)**:数据集中某一条记录，可以是关于一个事件或对象的描述。如：
> (色泽=青绿；根蒂=蜷缩；敲声=浊响)为一条记录，即一个示例，也可称为一个特征向量。

**属性或特征，属性值，属性空间(样本空间)**

**假设(hypothesis),真实(ground-truth)**
> 学习过程就是为了找出或逼近真相。

**标记(label)**: 关于示例结果的信息，比如一个瓜是好瓜还是坏瓜。*拥有了标记信息的示例，称为样例(example)*.

**sample != example**

学习到的模型适用于新样本的能力，称为**“泛化”(generalization)能力**.具有强泛化能力的模型能够很好地适用于整个样本空间。

## 1.2 假设空间
**归纳学习inductive learning**：是一种从特殊到一般的泛化过程，即从具体的事实归结出一般性规律。狭义上看，要求*从训练数据中学到概念concept*。

学习过程可以看作是 一个在所有假设hypothesis组成的空间中进行搜索的过程，搜索目标是*找到与训练集匹配的假设*。可能存在多个假设与训练集一致，此时其构成的假设集合被称为**版本空间version space**。
## 1.3 归纳偏好inductive bias：机器学习算法在学习过程中对某种类型假设的偏好
一个基本的算法选择原则-**奥卡姆剃刀Occam's razor**: 若存在多个假设与观察一致，则选择最简单的那个。

**没有免费的午餐(no free lunch)**:无论算法是复杂还是简单，它们的期望性能是相同的。换句话说：*一个精心设计的算法，其期望性能实际上和一个随机胡乱猜的算法是一样的*。但是，NFL Theorem有一个重要的前提：**所有的问题出现的机会相同、或所有问题同等重要**。这与实际情况是不符的。

NFL Theorem给人最重要的启示是：脱离具体问题，空谈“何种算法更好”是没有任何意义的。也就是说**必须在针对具体的学习问题上，讨论算法的优劣好坏才有意义**。

